{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249e3976-fa24-4d53-b8a0-8c0f31cd398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meerak/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/meerak/cxr_mimic/best_pretraining_Cardiomegaly/irpe.py:14: UserWarning: \u001b[91m[WARNING] The module `rpe_ops` is not built. For better training performance, please build `rpe_ops`.\u001b[00m\n",
      "  warnings.warn(RED_STR.format(\"[WARNING] The module `rpe_ops` is not built. \\\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from dataloader_helper import *\n",
    "from models import *\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "start = '/data2/meerak/models/'\n",
    "\n",
    "X_test, y_test = np.array(joblib.load('/data2/meerak/MIMIC_CXR_FTS/UPDATED_test_fts.joblib')), np.array(joblib.load('/data2/meerak/MIMIC_CXR_FTS/UPDATED_test_ys.joblib'))\n",
    "test_dg = CXRDataset('test', {'features':torch.tensor(X_test), 'labels':torch.tensor(y_test)})\n",
    "test_loader = DataLoader(test_dg,batch_size = 1,shuffle = False)\n",
    "\n",
    "def get_epoch(name):\n",
    "    title = 'best_%s.txt'%(name)\n",
    "    with open(title) as f:\n",
    "        count = 0\n",
    "        vals = []\n",
    "        tests = []\n",
    "        for line in f:\n",
    "            if count > 1:\n",
    "                vals.append(float(line.split(', ')[4]))\n",
    "                tests.append(float(line.split(', ')[5]))\n",
    "            if count == 1:\n",
    "                curr_params = line.split('\\n')[0]\n",
    "            count += 1\n",
    "    return np.argmax(vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf38614-a427-47a8-9e37-a700681ec3cf",
   "metadata": {},
   "source": [
    "### ABDMIL_NOPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8978f08-4b57-4791-b608-17c9cdfc4b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7817031184821799\n",
      "11.872807741165161\n",
      "0.782 (0.775, 0.789)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abdmil_nope.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cD = 2048\n",
    "model = ABDMIL(cD, PE = False).to(device)\n",
    "epoch = get_epoch('abdmil_nope')\n",
    "modelname = start + 'best_abdmil_nope_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "\n",
    "    bag_prediction = model(data)\n",
    "    \n",
    "    bag_preds.extend(F.softmax(bag_prediction, dim = 1)[:, 1].detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'abdmil_nope.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682be3a-9428-4d9c-a561-09b5d34fdcdc",
   "metadata": {},
   "source": [
    "### ABDMIL_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ffa47b-463b-4314-9099-278f801b7634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.798523189432873\n",
      "13.17552924156189\n",
      "0.798 (0.792, 0.806)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abdmil_pe.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cD = 4096\n",
    "model = ABDMIL(cD, PE = True).to(device)\n",
    "epoch = get_epoch('abdmil_pe')\n",
    "modelname = start + 'best_abdmil_pe_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "\n",
    "    bag_prediction = model(data)\n",
    "    \n",
    "    bag_preds.extend(F.softmax(bag_prediction, dim = 1)[:, 1].detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'abdmil_pe.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a09c9c9-fc8e-481a-bfae-cadc430c3a88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CLAM NOPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f645f6e-40d8-4c26-ada1-c3524cd62a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7808210386341587\n",
      "13.586225986480713\n",
      "0.780 (0.774, 0.788)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clamsb_nope.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cK = 6\n",
    "cDrop = 0 \n",
    "\n",
    "model = ClamWrapper(cK, cDrop, True, PE = False).to(device)\n",
    "epoch = get_epoch('clamSB_nope')\n",
    "modelname = start + 'best_clamSB_nope_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "model.eval()\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "\n",
    "    bag_prediction, inst_dict = model(data, target.to(torch.int64), instance_eval = False)\n",
    "    \n",
    "    bag_preds.extend(F.softmax(bag_prediction, dim = 1)[:, 1].detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'clamsb_nope.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dda110-d600-47ea-a65a-a58ff5a110c2",
   "metadata": {},
   "source": [
    "### CLAM PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "930973ac-587e-45ce-86d7-3089d9768d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7988378301214891\n",
      "15.412106275558472\n",
      "0.799 (0.792, 0.806)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clamsb_pe.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cK = 6\n",
    "cDrop = 0 \n",
    "\n",
    "model = ClamWrapper(cK, cDrop, True, PE = True).to(device)\n",
    "epoch = get_epoch('clamSB_pe')\n",
    "modelname = start + 'best_clamSB_pe_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "model.eval()\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "\n",
    "    bag_prediction, inst_dict = model(data, target.to(torch.int64), instance_eval = False)\n",
    "    \n",
    "    bag_preds.extend(F.softmax(bag_prediction, dim = 1)[:, 1].detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'clamsb_pe.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22728c8-e619-4ab2-ad77-a4602a0bca77",
   "metadata": {},
   "source": [
    "## CLAM MB NOPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d35333-c077-4241-8744-208bde8a8eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7782535313501515\n",
      "12.4870023727417\n",
      "0.778 (0.771, 0.786)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clammb_nope.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cK = 8\n",
    "cDrop = 0 \n",
    "\n",
    "model = ClamWrapper(cK, cDrop, True, PE = False).to(device)\n",
    "epoch = get_epoch('clamMB_nope')\n",
    "modelname = start + 'best_clamMB_nope_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "model.eval()\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "\n",
    "    bag_prediction, inst_dict = model(data, target.to(torch.int64), instance_eval = False)\n",
    "    \n",
    "    bag_preds.extend(F.softmax(bag_prediction, dim = 1)[:, 1].detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'clammb_nope.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e40c9b5-20b8-418a-bda0-6b8af0e9d705",
   "metadata": {},
   "source": [
    "## CLAM MB PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19966169-cba9-4ccd-9b22-4485a81418d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7978062184902243\n",
      "14.317506790161133\n",
      "0.798 (0.791, 0.805)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clammb_pe.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cK = 4\n",
    "cDrop = 0 \n",
    "\n",
    "model = ClamWrapper(cK, cDrop, True, PE = True).to(device)\n",
    "epoch = get_epoch('clamMB_pe')\n",
    "modelname = start + 'best_clamMB_pe_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "model.eval()\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "\n",
    "    bag_prediction, inst_dict = model(data, target.to(torch.int64), instance_eval = False)\n",
    "    \n",
    "    bag_preds.extend(F.softmax(bag_prediction, dim = 1)[:, 1].detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'clammb_pe.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63178b88-11c3-4517-b433-46ee7f7551ae",
   "metadata": {},
   "source": [
    "## DTFD NOPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ba0498-b934-47cc-9a83-55bc91c772db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7772931977830448\n",
      "48.343833684921265\n",
      "0.777 (0.770, 0.785)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dtfd_nope.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cD = 128\n",
    "cNPB = 4\n",
    "model = DTFD(cD, cNPB, PE = False).to(device)\n",
    "epoch = get_epoch('dtfd_nope')\n",
    "modelname = start + 'best_dtfd_nope_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "\n",
    "    bag_prediction, _ = model(data, target, criterion)\n",
    "    \n",
    "    bag_preds.extend(F.softmax(bag_prediction, dim = 1)[:, 1].detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'dtfd_nope.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d2f865-8190-498c-8bcb-abff097a13f0",
   "metadata": {},
   "source": [
    "## DTFD PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a855d21e-ab26-4225-8421-7aa66873858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7918336038439552\n",
      "46.30561542510986\n",
      "0.792 (0.785, 0.799)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dtfd_pe.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cD = 1024\n",
    "cNPB = 4\n",
    "model = DTFD(cD, cNPB, PE = True).to(device)\n",
    "epoch = get_epoch('dtfd_pe')\n",
    "modelname = start + 'best_dtfd_pe_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "\n",
    "    bag_prediction, _ = model(data, target, criterion, loss = False)\n",
    "    \n",
    "    bag_preds.extend(F.softmax(bag_prediction, dim = 1)[:, 1].detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'dtfd_pe.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563596b3-cea9-4f58-8a89-e6d33806022e",
   "metadata": {},
   "source": [
    "## SGL NO PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5576a13-5980-4fa3-ba5f-fea790ea13c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7549947161714602\n",
      "31.815017700195312\n",
      "0.755 (0.747, 0.764)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sgl_nope.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sgl_functions import*\n",
    "cD = 1024\n",
    "model = SGL_Model(cD, PE = False).to(device)\n",
    "epoch = get_epoch('sgl_nope')\n",
    "modelname = start + 'best_sgl_nope_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "    inst_pred = model(data)\n",
    "    bag_prediction = lin_soft(inst_pred.sigmoid())\n",
    "    \n",
    "    bag_preds.extend(bag_prediction.detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'sgl_nope.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924614a-b851-4710-a83b-e8e6e7b7da49",
   "metadata": {},
   "source": [
    "## SGL PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d398049-121a-4e84-ad82-50294169c563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7658301046542109\n",
      "32.290428161621094\n",
      "0.766 (0.758, 0.773)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sgl_pe.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sgl_functions import*\n",
    "cD = 1024\n",
    "model = SGL_Model(cD, PE = True).to(device)\n",
    "epoch = get_epoch('sgl_pe')\n",
    "modelname = start + 'best_sgl_pe_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "    inst_pred = model(data)\n",
    "    bag_prediction = lin_soft(inst_pred.sigmoid())\n",
    "    \n",
    "    bag_preds.extend(bag_prediction.detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'sgl_pe.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efadf7a2-3593-4902-9795-516313bb9b60",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "861f35e2-3509-44e9-8bcf-211073473ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7987075135987847\n",
      "93.23540759086609\n",
      "cls_token Nystrom False\n",
      "0.799 (0.792, 0.806)\n",
      "Test AUROC: 0.8027213618873578\n",
      "93.65480637550354\n",
      "cls_token Nystrom True\n",
      "0.803 (0.796, 0.809)\n",
      "Test AUROC: 0.7846019601725319\n",
      "24.940438985824585\n",
      "cls_token Orig False\n",
      "0.785 (0.777, 0.792)\n",
      "Test AUROC: 0.8048384946308439\n",
      "26.085609912872314\n",
      "cls_token Orig True\n",
      "0.805 (0.798, 0.812)\n"
     ]
    }
   ],
   "source": [
    "cD = 128\n",
    "for dict_attn in ['', '_orig']:\n",
    "    for dict_agg in ['']:\n",
    "        for dict_addPE in ['', '_pe']:\n",
    "\n",
    "            if dict_agg == '_max':\n",
    "                agg = 'max'\n",
    "            elif dict_agg == '_avg':\n",
    "                agg = 'avg'\n",
    "            elif dict_agg == '':\n",
    "                agg = 'cls_token'\n",
    "\n",
    "\n",
    "            if dict_attn == '_orig':\n",
    "                attn = 'Orig'\n",
    "            elif dict_attn == '':\n",
    "                attn = 'Nystrom'\n",
    "\n",
    "            if dict_addPE == '':\n",
    "                pe = False\n",
    "            elif dict_addPE == '_pe':\n",
    "                pe = True\n",
    "\n",
    "            model = Transformer(cD, agg, attn, PE = pe).to(device)\n",
    "            epoch = get_epoch('transformer%s%s%s'%(dict_attn, dict_agg, dict_addPE))\n",
    "            modelname = start + 'best_transformer%s%s%s_mimiccxr_densenet_epoch%d'%(dict_attn, dict_agg, dict_addPE, epoch)\n",
    "            model.load_state_dict(torch.load(modelname))\n",
    "\n",
    "            bag_preds = []\n",
    "            bag_ys = []\n",
    "            start_epoch = time.time()\n",
    "            for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "                data = data.to(device).squeeze(0)\n",
    "                target = target.to(device)\n",
    "\n",
    "                bag_prediction = model(data)\n",
    "\n",
    "                bag_preds.extend(F.softmax(bag_prediction, dim = 1)[:, 1].detach().cpu().numpy())\n",
    "                bag_ys.extend(target.detach().cpu().numpy())\n",
    "                del data\n",
    "                del bag_prediction\n",
    "            end_epoch = time.time()\n",
    "\n",
    "            bag_preds = np.array(bag_preds)\n",
    "            bag_ys = np.array(bag_ys)  \n",
    "            print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "            print(end_epoch - start_epoch)\n",
    "\n",
    "            curr_rocs = []\n",
    "            for _ in range(1000):\n",
    "                curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "                curr_bp = bag_preds[curr_idxs]\n",
    "                curr_y = bag_ys[curr_idxs]\n",
    "                curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "            curr_rocs.sort()\n",
    "            print(agg, attn, pe)\n",
    "            print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "\n",
    "                \n",
    "            joblib.dump(curr_rocs, 'transformer%s%s%s.joblib'%(dict_attn, dict_agg, dict_addPE))\n",
    "            \n",
    "            joblib.dump(bag_ys, 'bagy_transformer%s%s%s.joblib'%(dict_attn, dict_agg, dict_addPE))\n",
    "            \n",
    "            joblib.dump(bag_preds, 'bagpred_transformer%s%s%s.joblib'%(dict_attn, dict_agg, dict_addPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e84e89-ea0c-41b9-8810-a5b6f1e2a516",
   "metadata": {},
   "source": [
    "### TRANSMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "794cbacc-c4e2-431e-9a1b-05b5fa7f606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7987287473206001\n",
      "122.60532546043396\n",
      "0.799 (0.792, 0.806)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['transmil.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cD = 128\n",
    "model = TransMIL(cD).to(device)\n",
    "epoch = get_epoch('transmil_nope')\n",
    "modelname = start + 'best_transmil_mimiccxr_densenet_epoch%d'%epoch\n",
    "model.load_state_dict(torch.load(modelname))\n",
    "\n",
    "bag_preds = []\n",
    "bag_ys = []\n",
    "start_epoch = time.time()\n",
    "for batch_idx, (curridx, data, target) in enumerate(test_loader):\n",
    "    data = data.to(device).squeeze(0)\n",
    "    target = target.to(device)\n",
    "\n",
    "    bag_prediction = model(data)\n",
    "    \n",
    "    bag_preds.extend(F.softmax(bag_prediction, dim = 1)[:, 1].detach().cpu().numpy())\n",
    "    bag_ys.extend(target.detach().cpu().numpy())\n",
    "    del data\n",
    "    del bag_prediction\n",
    "end_epoch = time.time()\n",
    "\n",
    "bag_preds = np.array(bag_preds)\n",
    "bag_ys = np.array(bag_ys)  \n",
    "print('Test AUROC:', roc_auc_score(bag_ys, bag_preds))\n",
    "print(end_epoch - start_epoch)\n",
    "\n",
    "curr_rocs = []\n",
    "for _ in range(1000):\n",
    "    curr_idxs = np.random.choice(len(bag_preds), len(bag_preds))\n",
    "    curr_bp = bag_preds[curr_idxs]\n",
    "    curr_y = bag_ys[curr_idxs]\n",
    "    curr_rocs.append(roc_auc_score(curr_y, curr_bp))\n",
    "\n",
    "curr_rocs.sort()\n",
    "print('%0.3f (%0.3f, %0.3f)'%(curr_rocs[500], curr_rocs[25], curr_rocs[975]))\n",
    "joblib.dump(curr_rocs, 'transmil.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
